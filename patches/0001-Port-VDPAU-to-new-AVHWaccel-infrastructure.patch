From dc9810a541193a348d0805865e3058730b01bed4 Mon Sep 17 00:00:00 2001
From: Gwenole Beauchesne <gbeauchesne@splitted-desktop.com>
Date: Mon, 28 Mar 2011 12:37:03 +0200
Subject: [PATCH] Port VDPAU to new AVHWaccel infrastructure.

---
 libavcodec/allcodecs.c        |   13 +-
 libavcodec/avcodec.h          |    4 -
 libavcodec/error_resilience.c |    1 -
 libavcodec/h263dec.c          |    6 -
 libavcodec/h264.c             |   33 ----
 libavcodec/mpeg12.c           |   56 +------
 libavcodec/mpeg4videodec.c    |   17 --
 libavcodec/mpegvideo.c        |    3 +-
 libavcodec/vc1dec.c           |   52 +------
 libavcodec/vdpau.c            |  349 +++++++++++++++++++++++++++++++----------
 libavutil/pixdesc.c           |    6 +
 libavutil/pixfmt.h            |    1 +
 12 files changed, 287 insertions(+), 254 deletions(-)

diff --git a/libavcodec/allcodecs.c b/libavcodec/allcodecs.c
index 695b25b..0a70c10 100644
--- a/libavcodec/allcodecs.c
+++ b/libavcodec/allcodecs.c
@@ -65,6 +65,13 @@ void avcodec_register_all(void)
     REGISTER_HWACCEL (WMV3_DXVA2, wmv3_dxva2);
     REGISTER_HWACCEL (WMV3_VAAPI, wmv3_vaapi);
 
+    REGISTER_HWACCEL (H264_VDPAU, h264_vdpau);
+    REGISTER_HWACCEL (MPEG1_VDPAU, mpeg1_vdpau);
+    REGISTER_HWACCEL (MPEG2_VDPAU, mpeg2_vdpau);
+    REGISTER_HWACCEL (MPEG4_VDPAU, mpeg4_vdpau);
+    REGISTER_HWACCEL (VC1_VDPAU, vc1_vdpau);
+    REGISTER_HWACCEL (WMV3_VDPAU, wmv3_vdpau);
+
     /* video codecs */
     REGISTER_ENCODER (A64MULTI, a64multi);
     REGISTER_ENCODER (A64MULTI5, a64multi5);
@@ -117,7 +124,6 @@ void avcodec_register_all(void)
     REGISTER_ENCODER (H263P, h263p);
     REGISTER_DECODER (H264, h264);
     REGISTER_DECODER (H264_CRYSTALHD, h264_crystalhd);
-    REGISTER_DECODER (H264_VDPAU, h264_vdpau);
     REGISTER_ENCDEC  (HUFFYUV, huffyuv);
     REGISTER_DECODER (IDCIN, idcin);
     REGISTER_DECODER (IFF_BYTERUN1, iff_byterun1);
@@ -144,10 +150,7 @@ void avcodec_register_all(void)
     REGISTER_ENCDEC  (MPEG2VIDEO, mpeg2video);
     REGISTER_ENCDEC  (MPEG4, mpeg4);
     REGISTER_DECODER (MPEG4_CRYSTALHD, mpeg4_crystalhd);
-    REGISTER_DECODER (MPEG4_VDPAU, mpeg4_vdpau);
     REGISTER_DECODER (MPEGVIDEO, mpegvideo);
-    REGISTER_DECODER (MPEG_VDPAU, mpeg_vdpau);
-    REGISTER_DECODER (MPEG1_VDPAU, mpeg1_vdpau);
     REGISTER_DECODER (MPEG2_CRYSTALHD, mpeg2_crystalhd);
     REGISTER_DECODER (MSMPEG4_CRYSTALHD, msmpeg4_crystalhd);
     REGISTER_ENCDEC  (MSMPEG4V1, msmpeg4v1);
@@ -203,7 +206,6 @@ void avcodec_register_all(void)
     REGISTER_DECODER (VB, vb);
     REGISTER_DECODER (VC1, vc1);
     REGISTER_DECODER (VC1_CRYSTALHD, vc1_crystalhd);
-    REGISTER_DECODER (VC1_VDPAU, vc1_vdpau);
     REGISTER_DECODER (VCR1, vcr1);
     REGISTER_DECODER (VMDVIDEO, vmdvideo);
     REGISTER_DECODER (VMNC, vmnc);
@@ -218,7 +220,6 @@ void avcodec_register_all(void)
     REGISTER_ENCDEC  (WMV2, wmv2);
     REGISTER_DECODER (WMV3, wmv3);
     REGISTER_DECODER (WMV3_CRYSTALHD, wmv3_crystalhd);
-    REGISTER_DECODER (WMV3_VDPAU, wmv3_vdpau);
     REGISTER_DECODER (WNV1, wnv1);
     REGISTER_DECODER (XAN_WC3, xan_wc3);
     REGISTER_DECODER (XAN_WC4, xan_wc4);
diff --git a/libavcodec/avcodec.h b/libavcodec/avcodec.h
index 7ab02e6..2b8b459 100644
--- a/libavcodec/avcodec.h
+++ b/libavcodec/avcodec.h
@@ -664,10 +664,6 @@ typedef struct RcOverride{
  */
 #define CODEC_CAP_SMALL_LAST_FRAME 0x0040
 /**
- * Codec can export data for HW decoding (VDPAU).
- */
-#define CODEC_CAP_HWACCEL_VDPAU    0x0080
-/**
  * Codec can output multiple frames per AVPacket
  * Normally demuxers return one frame at a time, demuxers which do not do
  * are connected to a parser to split what they return into proper frames.
diff --git a/libavcodec/error_resilience.c b/libavcodec/error_resilience.c
index dc015b9..a36f7ac 100644
--- a/libavcodec/error_resilience.c
+++ b/libavcodec/error_resilience.c
@@ -759,7 +759,6 @@ void ff_er_frame_end(MpegEncContext *s){
 
     if(!s->error_recognition || s->error_count==0 || s->avctx->lowres ||
        s->avctx->hwaccel ||
-       s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU ||
        s->picture_structure != PICT_FRAME || // we dont support ER of field pictures yet, though it should not crash if enabled
        s->error_count==3*s->mb_width*(s->avctx->skip_top + s->avctx->skip_bottom)) return;
 
diff --git a/libavcodec/h263dec.c b/libavcodec/h263dec.c
index 4830202..4da778d 100644
--- a/libavcodec/h263dec.c
+++ b/libavcodec/h263dec.c
@@ -34,7 +34,6 @@
 #include "h263_parser.h"
 #include "mpeg4video_parser.h"
 #include "msmpeg4.h"
-#include "vdpau_internal.h"
 #include "thread.h"
 #include "flv.h"
 #include "mpeg4video.h"
@@ -644,11 +643,6 @@ retry:
 
     if (!s->divx_packed) ff_thread_finish_setup(avctx);
 
-    if (CONFIG_MPEG4_VDPAU_DECODER && (s->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU)) {
-        ff_vdpau_mpeg4_decode_picture(s, s->gb.buffer, s->gb.buffer_end - s->gb.buffer);
-        goto frame_end;
-    }
-
     if (avctx->hwaccel) {
         if (avctx->hwaccel->start_frame(avctx, s->gb.buffer, s->gb.buffer_end - s->gb.buffer) < 0)
             return -1;
diff --git a/libavcodec/h264.c b/libavcodec/h264.c
index d25b310..7841c31 100644
--- a/libavcodec/h264.c
+++ b/libavcodec/h264.c
@@ -37,7 +37,6 @@
 #include "mathops.h"
 #include "rectangle.h"
 #include "thread.h"
-#include "vdpau_internal.h"
 #include "libavutil/avassert.h"
 
 #include "cabac.h"
@@ -2025,8 +2024,6 @@ static void field_end(H264Context *h, int in_setup){
         ff_thread_report_progress((AVFrame*)s->current_picture_ptr, (16*s->mb_height >> FIELD_PICTURE) - 1,
                                  s->picture_structure==PICT_BOTTOM_FIELD);
 
-    if (CONFIG_H264_VDPAU_DECODER && s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)
-        ff_vdpau_h264_set_reference_frames(s);
 
     if(in_setup || !(avctx->active_thread_type&FF_THREAD_FRAME)){
         if(!s->dropable) {
@@ -2044,9 +2041,6 @@ static void field_end(H264Context *h, int in_setup){
             av_log(avctx, AV_LOG_ERROR, "hardware accelerator failed to decode picture\n");
     }
 
-    if (CONFIG_H264_VDPAU_DECODER && s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)
-        ff_vdpau_h264_picture_complete(s);
-
     /*
      * FIXME: Error handling code does not seem to support interlaced
      * when slices span multiple rows
@@ -3183,8 +3177,6 @@ static void execute_decode_slices(H264Context *h, int context_count){
 
     if (s->avctx->hwaccel)
         return;
-    if(s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)
-        return;
     if(context_count == 1) {
         decode_slice(avctx, &h);
     } else {
@@ -3323,8 +3315,6 @@ static int decode_nal_units(H264Context *h, const uint8_t *buf, int buf_size){
 
                 if (s->avctx->hwaccel && s->avctx->hwaccel->start_frame(s->avctx, NULL, 0) < 0)
                     return -1;
-                if(CONFIG_H264_VDPAU_DECODER && s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)
-                    ff_vdpau_h264_picture_start(s);
             }
 
             if(hx->redundant_pic_count==0 && hx->s.hurry_up < 5
@@ -3336,11 +3326,6 @@ static int decode_nal_units(H264Context *h, const uint8_t *buf, int buf_size){
                     if (avctx->hwaccel->decode_slice(avctx, &buf[buf_index - consumed], consumed) < 0)
                         return -1;
                 }else
-                if(CONFIG_H264_VDPAU_DECODER && s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU){
-                    static const uint8_t start_code[] = {0x00, 0x00, 0x01};
-                    ff_vdpau_add_data_chunk(s, start_code, sizeof(start_code));
-                    ff_vdpau_add_data_chunk(s, &buf[buf_index - consumed], consumed );
-                }else
                     context_count++;
             }
             break;
@@ -3771,21 +3756,3 @@ AVCodec ff_h264_decoder = {
     .update_thread_context = ONLY_IF_THREADS_ENABLED(decode_update_thread_context),
     .profiles = NULL_IF_CONFIG_SMALL(profiles),
 };
-
-#if CONFIG_H264_VDPAU_DECODER
-AVCodec ff_h264_vdpau_decoder = {
-    "h264_vdpau",
-    AVMEDIA_TYPE_VIDEO,
-    CODEC_ID_H264,
-    sizeof(H264Context),
-    ff_h264_decode_init,
-    NULL,
-    ff_h264_decode_end,
-    decode_frame,
-    CODEC_CAP_DR1 | CODEC_CAP_DELAY | CODEC_CAP_HWACCEL_VDPAU,
-    .flush= flush_dpb,
-    .long_name = NULL_IF_CONFIG_SMALL("H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (VDPAU acceleration)"),
-    .pix_fmts = (const enum PixelFormat[]){PIX_FMT_VDPAU_H264, PIX_FMT_NONE},
-    .profiles = NULL_IF_CONFIG_SMALL(profiles),
-};
-#endif
diff --git a/libavcodec/mpeg12.c b/libavcodec/mpeg12.c
index 5db24e8..4586655 100644
--- a/libavcodec/mpeg12.c
+++ b/libavcodec/mpeg12.c
@@ -35,7 +35,6 @@
 #include "mpeg12data.h"
 #include "mpeg12decdata.h"
 #include "bytestream.h"
-#include "vdpau_internal.h"
 #include "xvmc_internal.h"
 #include "thread.h"
 
@@ -1219,12 +1218,7 @@ static enum PixelFormat mpeg_get_pixelformat(AVCodecContext *avctx){
 
     if(avctx->xvmc_acceleration)
         return avctx->get_format(avctx,pixfmt_xvmc_mpg2_420);
-    else if(avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU){
-        if(avctx->codec_id == CODEC_ID_MPEG1VIDEO)
-            return PIX_FMT_VDPAU_MPEG1;
-        else
-            return PIX_FMT_VDPAU_MPEG2;
-    }else{
+    else{
         if(s->chroma_format <  2)
             return avctx->get_format(avctx,ff_hwaccel_pixfmt_list_420);
         else if(s->chroma_format == 2)
@@ -1333,9 +1327,7 @@ static int mpeg_decode_postinit(AVCodecContext *avctx){
         avctx->pix_fmt = mpeg_get_pixelformat(avctx);
         avctx->hwaccel = ff_find_hwaccel(avctx->codec->id, avctx->pix_fmt);
         //until then pix_fmt may be changed right after codec init
-        if( avctx->pix_fmt == PIX_FMT_XVMC_MPEG2_IDCT ||
-            avctx->hwaccel ||
-            s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU )
+        if( avctx->pix_fmt == PIX_FMT_XVMC_MPEG2_IDCT || avctx->hwaccel )
             if( avctx->idct_algo == FF_IDCT_AUTO )
                 avctx->idct_algo = FF_IDCT_SIMPLE;
 
@@ -2081,8 +2073,7 @@ static int vcr2_init_sequence(AVCodecContext *avctx)
     avctx->pix_fmt = mpeg_get_pixelformat(avctx);
     avctx->hwaccel = ff_find_hwaccel(avctx->codec->id, avctx->pix_fmt);
 
-    if( avctx->pix_fmt == PIX_FMT_XVMC_MPEG2_IDCT || avctx->hwaccel ||
-        s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU )
+    if( avctx->pix_fmt == PIX_FMT_XVMC_MPEG2_IDCT || avctx->hwaccel )
         if( avctx->idct_algo == FF_IDCT_AUTO )
             avctx->idct_algo = FF_IDCT_SIMPLE;
 
@@ -2313,9 +2304,6 @@ static int decode_chunks(AVCodecContext *avctx,
                         s2->error_count += s2->thread_context[i]->error_count;
                 }
 
-                if (CONFIG_MPEG_VDPAU_DECODER && avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)
-                    ff_vdpau_mpeg_picture_complete(s2, buf, buf_size, s->slice_count);
-
                 if (slice_end(avctx, picture)) {
                     if(s2->last_picture_ptr || s2->low_delay) //FIXME merge with the stuff in mpeg_decode_slice
                         *data_size = sizeof(AVPicture);
@@ -2472,11 +2460,6 @@ static int decode_chunks(AVCodecContext *avctx,
                     return -1;
                 }
 
-                if (avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU) {
-                    s->slice_count++;
-                    break;
-                }
-
                 if(HAVE_THREADS && avctx->active_thread_type&FF_THREAD_SLICE){
                     int threshold= (s2->mb_height*s->slice_count + avctx->thread_count/2) / avctx->thread_count;
                     if(threshold <= mb_y){
@@ -2618,36 +2601,3 @@ AVCodec ff_mpeg_xvmc_decoder = {
 };
 
 #endif
-
-#if CONFIG_MPEG_VDPAU_DECODER
-AVCodec ff_mpeg_vdpau_decoder = {
-    "mpegvideo_vdpau",
-    AVMEDIA_TYPE_VIDEO,
-    CODEC_ID_MPEG2VIDEO,
-    sizeof(Mpeg1Context),
-    mpeg_decode_init,
-    NULL,
-    mpeg_decode_end,
-    mpeg_decode_frame,
-    CODEC_CAP_DR1 | CODEC_CAP_TRUNCATED | CODEC_CAP_HWACCEL_VDPAU | CODEC_CAP_DELAY,
-    .flush= flush,
-    .long_name = NULL_IF_CONFIG_SMALL("MPEG-1/2 video (VDPAU acceleration)"),
-};
-#endif
-
-#if CONFIG_MPEG1_VDPAU_DECODER
-AVCodec ff_mpeg1_vdpau_decoder = {
-    "mpeg1video_vdpau",
-    AVMEDIA_TYPE_VIDEO,
-    CODEC_ID_MPEG1VIDEO,
-    sizeof(Mpeg1Context),
-    mpeg_decode_init,
-    NULL,
-    mpeg_decode_end,
-    mpeg_decode_frame,
-    CODEC_CAP_DR1 | CODEC_CAP_TRUNCATED | CODEC_CAP_HWACCEL_VDPAU | CODEC_CAP_DELAY,
-    .flush= flush,
-    .long_name = NULL_IF_CONFIG_SMALL("MPEG-1 video (VDPAU acceleration)"),
-};
-#endif
-
diff --git a/libavcodec/mpeg4videodec.c b/libavcodec/mpeg4videodec.c
index b293bad..a91d9d3 100644
--- a/libavcodec/mpeg4videodec.c
+++ b/libavcodec/mpeg4videodec.c
@@ -2261,20 +2261,3 @@ AVCodec ff_mpeg4_decoder = {
     .pix_fmts= ff_hwaccel_pixfmt_list_420,
     .update_thread_context= ONLY_IF_THREADS_ENABLED(ff_mpeg_update_thread_context)
 };
-
-
-#if CONFIG_MPEG4_VDPAU_DECODER
-AVCodec ff_mpeg4_vdpau_decoder = {
-    "mpeg4_vdpau",
-    AVMEDIA_TYPE_VIDEO,
-    CODEC_ID_MPEG4,
-    sizeof(MpegEncContext),
-    decode_init,
-    NULL,
-    ff_h263_decode_end,
-    ff_h263_decode_frame,
-    CODEC_CAP_DR1 | CODEC_CAP_TRUNCATED | CODEC_CAP_DELAY | CODEC_CAP_HWACCEL_VDPAU,
-    .long_name= NULL_IF_CONFIG_SMALL("MPEG-4 part 2 (VDPAU)"),
-    .pix_fmts= (const enum PixelFormat[]){PIX_FMT_VDPAU_MPEG4, PIX_FMT_NONE},
-};
-#endif
diff --git a/libavcodec/mpegvideo.c b/libavcodec/mpegvideo.c
index dd003b4..19deace 100644
--- a/libavcodec/mpegvideo.c
+++ b/libavcodec/mpegvideo.c
@@ -118,6 +118,7 @@ const enum PixelFormat ff_pixfmt_list_420[] = {
 const enum PixelFormat ff_hwaccel_pixfmt_list_420[] = {
     PIX_FMT_DXVA2_VLD,
     PIX_FMT_VAAPI_VLD,
+    PIX_FMT_VDPAU,
     PIX_FMT_YUV420P,
     PIX_FMT_NONE
 };
@@ -1158,7 +1159,6 @@ void MPV_frame_end(MpegEncContext *s)
         ff_xvmc_field_end(s);
    }else if((s->error_count || s->encoding)
        && !s->avctx->hwaccel
-       && !(s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)
        && s->unrestricted_mv
        && s->current_picture.reference
        && !s->intra_only
@@ -2254,7 +2254,6 @@ void ff_draw_horiz_band(MpegEncContext *s, int y, int h){
     }
 
     if (!s->avctx->hwaccel
-       && !(s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)
        && s->unrestricted_mv
        && s->current_picture.reference
        && !s->intra_only
diff --git a/libavcodec/vc1dec.c b/libavcodec/vc1dec.c
index 4bc7c9d..2510747 100644
--- a/libavcodec/vc1dec.c
+++ b/libavcodec/vc1dec.c
@@ -37,7 +37,6 @@
 #include "unary.h"
 #include "simple_idct.h"
 #include "mathops.h"
-#include "vdpau_internal.h"
 
 #undef NDEBUG
 #include <assert.h>
@@ -3290,13 +3289,6 @@ static int vc1_decode_frame(AVCodecContext *avctx,
         s->current_picture_ptr= &s->picture[i];
     }
 
-    if (s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU){
-        if (v->profile < PROFILE_ADVANCED)
-            avctx->pix_fmt = PIX_FMT_VDPAU_WMV3;
-        else
-            avctx->pix_fmt = PIX_FMT_VDPAU_VC1;
-    }
-
     //for advanced profile we may need to parse and unescape data
     if (avctx->codec_id == CODEC_ID_VC1) {
         int buf_size2 = 0;
@@ -3313,8 +3305,7 @@ static int vc1_decode_frame(AVCodecContext *avctx,
                 if(size <= 0) continue;
                 switch(AV_RB32(start)){
                 case VC1_CODE_FRAME:
-                    if (avctx->hwaccel ||
-                        s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)
+                    if (avctx->hwaccel)
                         buf_start = start;
                     buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);
                     break;
@@ -3408,10 +3399,7 @@ static int vc1_decode_frame(AVCodecContext *avctx,
     s->me.qpel_put= s->dsp.put_qpel_pixels_tab;
     s->me.qpel_avg= s->dsp.avg_qpel_pixels_tab;
 
-    if ((CONFIG_VC1_VDPAU_DECODER)
-        &&s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)
-        ff_vdpau_vc1_decode_picture(s, buf_start, (buf + buf_size) - buf_start);
-    else if (avctx->hwaccel) {
+    if (avctx->hwaccel) {
         if (avctx->hwaccel->start_frame(avctx, buf, buf_size) < 0)
             goto err;
         if (avctx->hwaccel->decode_slice(avctx, buf_start, (buf + buf_size) - buf_start) < 0)
@@ -3530,39 +3518,3 @@ AVCodec ff_wmv3_decoder = {
     .profiles = NULL_IF_CONFIG_SMALL(profiles)
 };
 #endif
-
-#if CONFIG_WMV3_VDPAU_DECODER
-AVCodec ff_wmv3_vdpau_decoder = {
-    "wmv3_vdpau",
-    AVMEDIA_TYPE_VIDEO,
-    CODEC_ID_WMV3,
-    sizeof(VC1Context),
-    vc1_decode_init,
-    NULL,
-    vc1_decode_end,
-    vc1_decode_frame,
-    CODEC_CAP_DR1 | CODEC_CAP_DELAY | CODEC_CAP_HWACCEL_VDPAU,
-    NULL,
-    .long_name = NULL_IF_CONFIG_SMALL("Windows Media Video 9 VDPAU"),
-    .pix_fmts = (const enum PixelFormat[]){PIX_FMT_VDPAU_WMV3, PIX_FMT_NONE},
-    .profiles = NULL_IF_CONFIG_SMALL(profiles)
-};
-#endif
-
-#if CONFIG_VC1_VDPAU_DECODER
-AVCodec ff_vc1_vdpau_decoder = {
-    "vc1_vdpau",
-    AVMEDIA_TYPE_VIDEO,
-    CODEC_ID_VC1,
-    sizeof(VC1Context),
-    vc1_decode_init,
-    NULL,
-    vc1_decode_end,
-    vc1_decode_frame,
-    CODEC_CAP_DR1 | CODEC_CAP_DELAY | CODEC_CAP_HWACCEL_VDPAU,
-    NULL,
-    .long_name = NULL_IF_CONFIG_SMALL("SMPTE VC-1 VDPAU"),
-    .pix_fmts = (const enum PixelFormat[]){PIX_FMT_VDPAU_VC1, PIX_FMT_NONE},
-    .profiles = NULL_IF_CONFIG_SMALL(profiles)
-};
-#endif
diff --git a/libavcodec/vdpau.c b/libavcodec/vdpau.c
index bd721e8..9c7c66e 100644
--- a/libavcodec/vdpau.c
+++ b/libavcodec/vdpau.c
@@ -30,7 +30,6 @@
 #include <assert.h>
 
 #include "vdpau.h"
-#include "vdpau_internal.h"
 
 /**
  * \addtogroup VDPAU_Decoding
@@ -38,15 +37,57 @@
  * @{
  */
 
-void ff_vdpau_h264_set_reference_frames(MpegEncContext *s)
+static void vdpau_h264_fill_field_order_cnt(int32_t field_order_cnt[2], Picture *pic, int pic_structure)
 {
-    H264Context *h = s->avctx->priv_data;
+    int i;
+    for (i = 0; i < 2; i++) {
+        const int poc = pic->field_poc[i];
+        field_order_cnt[i] = poc != INT_MAX ? poc : 0;
+    }
+}
+
+static void vdpau_h264_init_picture(VdpReferenceFrameH264 *rf)
+{
+    rf->surface             = VDP_INVALID_HANDLE;
+    rf->is_long_term        = 0;
+    rf->top_is_reference    = 0;
+    rf->bottom_is_reference = 0;
+    rf->field_order_cnt[0]  = 0;
+    rf->field_order_cnt[1]  = 0;
+    rf->frame_idx           = 0;
+}
+
+static void vdpau_h264_fill_picture(VdpReferenceFrameH264 *rf, Picture *pic, int pic_structure)
+{
+    struct vdpau_render_state *render;
+
+    assert(rf);
+    assert(pic);
+
+    if (pic_structure == 0)
+        pic_structure = pic->reference;
+
+    render = (struct vdpau_render_state *)pic->data[3];
+    assert(render);
+
+    rf->surface             = render->surface;
+    rf->is_long_term        = pic->reference && pic->long_ref;
+    rf->top_is_reference    = (pic_structure & PICT_TOP_FIELD) != 0;
+    rf->bottom_is_reference = (pic_structure & PICT_BOTTOM_FIELD) != 0;
+    rf->frame_idx           = pic->long_ref ? pic->pic_id : pic->frame_num;
+
+    vdpau_h264_fill_field_order_cnt(rf->field_order_cnt, pic, pic_structure);
+}
+
+static void vdpau_h264_set_reference_frames(H264Context *h)
+{
+    MpegEncContext * const s = &h->s;
     struct vdpau_render_state *render, *render_ref;
     VdpReferenceFrameH264 *rf, *rf2;
     Picture *pic;
     int i, list, pic_frame_idx;
 
-    render = (struct vdpau_render_state *)s->current_picture_ptr->data[0];
+    render = (struct vdpau_render_state *)s->current_picture_ptr->data[3];
     assert(render);
 
     rf = &render->info.h264.referenceFrames[0];
@@ -62,7 +103,7 @@ void ff_vdpau_h264_set_reference_frames(MpegEncContext *s)
                 continue;
             pic_frame_idx = pic->long_ref ? pic->pic_id : pic->frame_num;
 
-            render_ref = (struct vdpau_render_state *)pic->data[0];
+            render_ref = (struct vdpau_render_state *)pic->data[3];
             assert(render_ref);
 
             rf2 = &render->info.h264.referenceFrames[0];
@@ -84,81 +125,93 @@ void ff_vdpau_h264_set_reference_frames(MpegEncContext *s)
             if (rf >= &render->info.h264.referenceFrames[H264_RF_COUNT])
                 continue;
 
-            rf->surface             = render_ref->surface;
-            rf->is_long_term        = pic->long_ref;
-            rf->top_is_reference    = (pic->reference & PICT_TOP_FIELD)    ? VDP_TRUE : VDP_FALSE;
-            rf->bottom_is_reference = (pic->reference & PICT_BOTTOM_FIELD) ? VDP_TRUE : VDP_FALSE;
-            rf->field_order_cnt[0]  = pic->field_poc[0];
-            rf->field_order_cnt[1]  = pic->field_poc[1];
-            rf->frame_idx           = pic_frame_idx;
+            vdpau_h264_fill_picture(rf, pic, pic->reference);
 
             ++rf;
         }
     }
 
-    for (; rf < &render->info.h264.referenceFrames[H264_RF_COUNT]; ++rf) {
-        rf->surface             = VDP_INVALID_HANDLE;
-        rf->is_long_term        = 0;
-        rf->top_is_reference    = 0;
-        rf->bottom_is_reference = 0;
-        rf->field_order_cnt[0]  = 0;
-        rf->field_order_cnt[1]  = 0;
-        rf->frame_idx           = 0;
-    }
+    for (; rf < &render->info.h264.referenceFrames[H264_RF_COUNT]; ++rf)
+        vdpau_h264_init_picture(rf);
 }
 
-void ff_vdpau_add_data_chunk(MpegEncContext *s,
-                             const uint8_t *buf, int buf_size)
+static int vdpau_ensure_bitstream_buffers(struct vdpau_render_state *render)
 {
-    struct vdpau_render_state *render;
-
-    render = (struct vdpau_render_state *)s->current_picture_ptr->data[0];
-    assert(render);
-
     render->bitstream_buffers= av_fast_realloc(
         render->bitstream_buffers,
         &render->bitstream_buffers_allocated,
         sizeof(*render->bitstream_buffers)*(render->bitstream_buffers_used + 1)
     );
 
-    render->bitstream_buffers[render->bitstream_buffers_used].struct_version  = VDP_BITSTREAM_BUFFER_VERSION;
-    render->bitstream_buffers[render->bitstream_buffers_used].bitstream       = buf;
-    render->bitstream_buffers[render->bitstream_buffers_used].bitstream_bytes = buf_size;
-    render->bitstream_buffers_used++;
+    if (!render->bitstream_buffers)
+        return -1;
+
+    return 0;
 }
 
-void ff_vdpau_h264_picture_start(MpegEncContext *s)
+static int vdpau_common_start_frame(AVCodecContext *avctx, av_unused const uint8_t *buffer, av_unused uint32_t size)
 {
-    H264Context *h = s->avctx->priv_data;
+    MpegEncContext * const s = avctx->priv_data;
     struct vdpau_render_state *render;
-    int i;
 
-    render = (struct vdpau_render_state *)s->current_picture_ptr->data[0];
+    render = (struct vdpau_render_state *)s->current_picture_ptr->data[3];
     assert(render);
 
-    for (i = 0; i < 2; ++i) {
-        int foc = s->current_picture_ptr->field_poc[i];
-        if (foc == INT_MAX)
-            foc = 0;
-        render->info.h264.field_order_cnt[i] = foc;
+    render->bitstream_buffers_used = 0;
+    return 0;
+}
+
+static int vdpau_common_end_frame(AVCodecContext *avctx)
+{
+    MpegEncContext * const s = avctx->priv_data;
+    struct vdpau_render_state *render;
+
+    render = (struct vdpau_render_state *)s->current_picture_ptr->data[3];
+    assert(render);
+
+    if (render->bitstream_buffers_used) {
+        ff_draw_horiz_band(s, 0, s->avctx->height);
+        render->bitstream_buffers_used = 0;
     }
+    return 0;
+}
+
+static int vdpau_common_decode_slice(AVCodecContext *avctx, const uint8_t *buf, uint32_t buf_size)
+{
+    MpegEncContext * const s = avctx->priv_data;
+    struct vdpau_render_state *render;
 
-    render->info.h264.frame_num = h->frame_num;
+    render = (struct vdpau_render_state *)s->current_picture_ptr->data[3];
+    assert(render);
+
+    if (vdpau_ensure_bitstream_buffers(render) < 0)
+        return -1;
+
+    render->bitstream_buffers[render->bitstream_buffers_used].struct_version  = VDP_BITSTREAM_BUFFER_VERSION;
+    render->bitstream_buffers[render->bitstream_buffers_used].bitstream       = buf;
+    render->bitstream_buffers[render->bitstream_buffers_used].bitstream_bytes = buf_size;
+    render->bitstream_buffers_used++;
+    return 0;
 }
 
-void ff_vdpau_h264_picture_complete(MpegEncContext *s)
+static int vdpau_h264_start_frame(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)
 {
-    H264Context *h = s->avctx->priv_data;
+    H264Context * const h = avctx->priv_data;
+    MpegEncContext * const s = &h->s;
     struct vdpau_render_state *render;
 
-    render = (struct vdpau_render_state *)s->current_picture_ptr->data[0];
+    render = (struct vdpau_render_state *)s->current_picture_ptr->data[3];
     assert(render);
 
-    render->info.h264.slice_count = h->slice_num;
-    if (render->info.h264.slice_count < 1)
-        return;
+    vdpau_h264_set_reference_frames(h);
+
+    vdpau_h264_fill_field_order_cnt(render->info.h264.field_order_cnt,
+                                    s->current_picture_ptr,
+                                    s->picture_structure);
 
-    render->info.h264.is_reference                           = (s->current_picture_ptr->reference & 3) ? VDP_TRUE : VDP_FALSE;
+    /* fill VdpPictureInfoH264 struct */
+    render->info.h264.is_reference                           = h->nal_ref_idc != 0;
+    render->info.h264.frame_num                              = h->frame_num;
     render->info.h264.field_pic_flag                         = s->picture_structure != PICT_FRAME;
     render->info.h264.bottom_field_flag                      = s->picture_structure == PICT_BOTTOM_FIELD;
     render->info.h264.num_ref_frames                         = h->sps.ref_frame_count;
@@ -185,19 +238,44 @@ void ff_vdpau_h264_picture_complete(MpegEncContext *s)
     memcpy(render->info.h264.scaling_lists_4x4, h->pps.scaling_matrix4, sizeof(render->info.h264.scaling_lists_4x4));
     memcpy(render->info.h264.scaling_lists_8x8, h->pps.scaling_matrix8, sizeof(render->info.h264.scaling_lists_8x8));
 
-    ff_draw_horiz_band(s, 0, s->avctx->height);
-    render->bitstream_buffers_used = 0;
+    render->info.h264.slice_count                = 0;
+
+    return vdpau_common_start_frame(avctx, buffer, size);
+}
+
+static int vdpau_h264_decode_slice(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)
+{
+    MpegEncContext * const s = avctx->priv_data;
+    struct vdpau_render_state *render;
+    static const uint8_t start_code_prefix_one_3byte[3] = { 0x00, 0x00, 0x01 };
+
+    render = (struct vdpau_render_state *)s->current_picture_ptr->data[3];
+    assert(render);
+
+    if (vdpau_ensure_bitstream_buffers(render) < 0)
+        return -1;
+
+    render->bitstream_buffers[render->bitstream_buffers_used].struct_version  = VDP_BITSTREAM_BUFFER_VERSION;
+    render->bitstream_buffers[render->bitstream_buffers_used].bitstream       = start_code_prefix_one_3byte;
+    render->bitstream_buffers[render->bitstream_buffers_used].bitstream_bytes = sizeof(start_code_prefix_one_3byte);
+    render->bitstream_buffers_used++;
+
+    if (vdpau_common_decode_slice(avctx, buffer, size) < 0)
+        return -1;
+
+    ++render->info.h264.slice_count;
+    return 0;
 }
 
-void ff_vdpau_mpeg_picture_complete(MpegEncContext *s, const uint8_t *buf,
-                                    int buf_size, int slice_count)
+static int vdpau_mpeg2_start_frame(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)
 {
+    MpegEncContext * const s = avctx->priv_data;
     struct vdpau_render_state *render, *last, *next;
     int i;
 
-    if (!s->current_picture_ptr) return;
+    if (!s->current_picture_ptr) return 0;
 
-    render = (struct vdpau_render_state *)s->current_picture_ptr->data[0];
+    render = (struct vdpau_render_state *)s->current_picture_ptr->data[3];
     assert(render);
 
     /* fill VdpPictureInfoMPEG1Or2 struct */
@@ -226,36 +304,47 @@ void ff_vdpau_mpeg_picture_complete(MpegEncContext *s, const uint8_t *buf,
 
     switch(s->pict_type){
     case  FF_B_TYPE:
-        next = (struct vdpau_render_state *)s->next_picture.data[0];
+        next = (struct vdpau_render_state *)s->next_picture.data[3];
         assert(next);
         render->info.mpeg.backward_reference     = next->surface;
         // no return here, going to set forward prediction
     case  FF_P_TYPE:
-        last = (struct vdpau_render_state *)s->last_picture.data[0];
+        last = (struct vdpau_render_state *)s->last_picture.data[3];
         if (!last) // FIXME: Does this test make sense?
             last = render; // predict second field from the first
         render->info.mpeg.forward_reference      = last->surface;
     }
 
-    ff_vdpau_add_data_chunk(s, buf, buf_size);
+    render->info.mpeg.slice_count                = 0;
 
-    render->info.mpeg.slice_count                = slice_count;
+    return vdpau_common_start_frame(avctx, buffer, size);
+}
 
-    if (slice_count)
-        ff_draw_horiz_band(s, 0, s->avctx->height);
-    render->bitstream_buffers_used               = 0;
+static int vdpau_mpeg2_decode_slice(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)
+{
+    MpegEncContext * const s = avctx->priv_data;
+    struct vdpau_render_state *render;
+
+    render = (struct vdpau_render_state *)s->current_picture_ptr->data[3];
+    assert(render);
+
+    if (vdpau_common_decode_slice(avctx, buffer, size) < 0)
+        return -1;
+
+    ++render->info.mpeg.slice_count;
+    return 0;
 }
 
-void ff_vdpau_vc1_decode_picture(MpegEncContext *s, const uint8_t *buf,
-                                 int buf_size)
+static int vdpau_vc1_start_frame(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)
 {
-    VC1Context *v = s->avctx->priv_data;
+    VC1Context * const v = avctx->priv_data;
+    MpegEncContext * const s = &v->s;
     struct vdpau_render_state *render, *last, *next;
 
-    render = (struct vdpau_render_state *)s->current_picture.data[0];
+    render = (struct vdpau_render_state *)s->current_picture_ptr->data[3];
     assert(render);
 
-    /*  fill LvPictureInfoVC1 struct */
+    /* fill VdpPictureInfoVC1 struct */
     render->info.vc1.frame_coding_mode  = v->fcm;
     render->info.vc1.postprocflag       = v->postprocflag;
     render->info.vc1.pulldown           = v->broadcast;
@@ -296,34 +385,47 @@ void ff_vdpau_vc1_decode_picture(MpegEncContext *s, const uint8_t *buf,
 
     switch(s->pict_type){
     case  FF_B_TYPE:
-        next = (struct vdpau_render_state *)s->next_picture.data[0];
+        next = (struct vdpau_render_state *)s->next_picture.data[3];
         assert(next);
         render->info.vc1.backward_reference = next->surface;
         // no break here, going to set forward prediction
     case  FF_P_TYPE:
-        last = (struct vdpau_render_state *)s->last_picture.data[0];
+        last = (struct vdpau_render_state *)s->last_picture.data[3];
         if (!last) // FIXME: Does this test make sense?
             last = render; // predict second field from the first
         render->info.vc1.forward_reference = last->surface;
     }
 
-    ff_vdpau_add_data_chunk(s, buf, buf_size);
+    render->info.vc1.slice_count                 = 0;
 
-    render->info.vc1.slice_count          = 1;
+    return vdpau_common_start_frame(avctx, buffer, size);
+}
 
-    ff_draw_horiz_band(s, 0, s->avctx->height);
-    render->bitstream_buffers_used        = 0;
+static int vdpau_vc1_decode_slice(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)
+{
+    VC1Context * const v = avctx->priv_data;
+    MpegEncContext * const s = &v->s;
+    struct vdpau_render_state *render;
+
+    render = (struct vdpau_render_state *)s->current_picture_ptr->data[3];
+    assert(render);
+
+    if (vdpau_common_decode_slice(avctx, buffer, size) < 0)
+        return -1;
+
+    ++render->info.vc1.slice_count;
+    return 0;
 }
 
-void ff_vdpau_mpeg4_decode_picture(MpegEncContext *s, const uint8_t *buf,
-                                   int buf_size)
+static int vdpau_mpeg4_start_frame(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)
 {
+    MpegEncContext * const s = avctx->priv_data;
     struct vdpau_render_state *render, *last, *next;
     int i;
 
-    if (!s->current_picture_ptr) return;
+    if (!s->current_picture_ptr) return 0;
 
-    render = (struct vdpau_render_state *)s->current_picture_ptr->data[0];
+    render = (struct vdpau_render_state *)s->current_picture_ptr->data[3];
     assert(render);
 
     /* fill VdpPictureInfoMPEG4Part2 struct */
@@ -352,21 +454,104 @@ void ff_vdpau_mpeg4_decode_picture(MpegEncContext *s, const uint8_t *buf,
 
     switch (s->pict_type) {
     case FF_B_TYPE:
-        next = (struct vdpau_render_state *)s->next_picture.data[0];
+        next = (struct vdpau_render_state *)s->next_picture.data[3];
         assert(next);
         render->info.mpeg4.backward_reference     = next->surface;
         render->info.mpeg4.vop_coding_type        = 2;
         // no break here, going to set forward prediction
     case FF_P_TYPE:
-        last = (struct vdpau_render_state *)s->last_picture.data[0];
+        last = (struct vdpau_render_state *)s->last_picture.data[3];
         assert(last);
         render->info.mpeg4.forward_reference      = last->surface;
     }
 
-    ff_vdpau_add_data_chunk(s, buf, buf_size);
+    if (vdpau_common_start_frame(avctx, buffer, size) < 0)
+        return -1;
 
-    ff_draw_horiz_band(s, 0, s->avctx->height);
-    render->bitstream_buffers_used = 0;
+    return vdpau_common_decode_slice(avctx, buffer, size);
 }
 
+static int vdpau_mpeg4_decode_slice(av_unused AVCodecContext *avctx, av_unused const uint8_t *buffer, av_unused uint32_t size)
+{
+    return 0;
+}
+
+#if CONFIG_MPEG1_VDPAU_HWACCEL
+AVHWAccel ff_mpeg1_vdpau_hwaccel = {
+    .name           = "mpeg1_vdpau",
+    .type           = CODEC_TYPE_VIDEO,
+    .id             = CODEC_ID_MPEG1VIDEO,
+    .pix_fmt        = PIX_FMT_VDPAU,
+    .capabilities   = 0,
+    .start_frame    = vdpau_mpeg2_start_frame,
+    .end_frame      = vdpau_common_end_frame,
+    .decode_slice   = vdpau_mpeg2_decode_slice,
+};
+#endif
+
+#if CONFIG_MPEG2_VDPAU_HWACCEL
+AVHWAccel ff_mpeg2_vdpau_hwaccel = {
+    .name           = "mpeg2_vdpau",
+    .type           = CODEC_TYPE_VIDEO,
+    .id             = CODEC_ID_MPEG2VIDEO,
+    .pix_fmt        = PIX_FMT_VDPAU,
+    .capabilities   = 0,
+    .start_frame    = vdpau_mpeg2_start_frame,
+    .end_frame      = vdpau_common_end_frame,
+    .decode_slice   = vdpau_mpeg2_decode_slice,
+};
+#endif
+
+#if CONFIG_H264_VDPAU_HWACCEL
+AVHWAccel ff_h264_vdpau_hwaccel = {
+    .name           = "h264_vdpau",
+    .type           = CODEC_TYPE_VIDEO,
+    .id             = CODEC_ID_H264,
+    .pix_fmt        = PIX_FMT_VDPAU,
+    .capabilities   = 0,
+    .start_frame    = vdpau_h264_start_frame,
+    .end_frame      = vdpau_common_end_frame,
+    .decode_slice   = vdpau_h264_decode_slice,
+};
+#endif
+
+#if CONFIG_WMV3_VDPAU_HWACCEL
+AVHWAccel ff_wmv3_vdpau_hwaccel = {
+    .name           = "wmv3_vdpau",
+    .type           = CODEC_TYPE_VIDEO,
+    .id             = CODEC_ID_WMV3,
+    .pix_fmt        = PIX_FMT_VDPAU,
+    .capabilities   = 0,
+    .start_frame    = vdpau_vc1_start_frame,
+    .end_frame      = vdpau_common_end_frame,
+    .decode_slice   = vdpau_vc1_decode_slice,
+};
+#endif
+
+#if CONFIG_VC1_VDPAU_HWACCEL
+AVHWAccel ff_vc1_vdpau_hwaccel = {
+    .name           = "vc1_vdpau",
+    .type           = CODEC_TYPE_VIDEO,
+    .id             = CODEC_ID_VC1,
+    .pix_fmt        = PIX_FMT_VDPAU,
+    .capabilities   = 0,
+    .start_frame    = vdpau_vc1_start_frame,
+    .end_frame      = vdpau_common_end_frame,
+    .decode_slice   = vdpau_vc1_decode_slice,
+};
+#endif
+
+#if CONFIG_MPEG4_VDPAU_HWACCEL
+AVHWAccel ff_mpeg4_vdpau_hwaccel = {
+    .name           = "mpeg4_vdpau",
+    .type           = CODEC_TYPE_VIDEO,
+    .id             = CODEC_ID_MPEG4,
+    .pix_fmt        = PIX_FMT_VDPAU,
+    .capabilities   = 0,
+    .start_frame    = vdpau_mpeg4_start_frame,
+    .end_frame      = vdpau_common_end_frame,
+    .decode_slice   = vdpau_mpeg4_decode_slice,
+};
+#endif
+
 /* @}*/
diff --git a/libavutil/pixdesc.c b/libavutil/pixdesc.c
index 82dda06..ecc8ab4 100644
--- a/libavutil/pixdesc.c
+++ b/libavutil/pixdesc.c
@@ -823,6 +823,12 @@ const AVPixFmtDescriptor av_pix_fmt_descriptors[PIX_FMT_NB] = {
             {0,1,2,0,7},        /* A */
         },
     },
+    [PIX_FMT_VDPAU] = {
+        .name = "vdpau",
+        .log2_chroma_w = 1,
+        .log2_chroma_h = 1,
+        .flags = PIX_FMT_HWACCEL,
+    },
 };
 
 static enum PixelFormat get_pix_fmt_internal(const char *name)
diff --git a/libavutil/pixfmt.h b/libavutil/pixfmt.h
index 69c6274..6fdd511 100644
--- a/libavutil/pixfmt.h
+++ b/libavutil/pixfmt.h
@@ -135,6 +135,7 @@ enum PixelFormat {
     PIX_FMT_Y400A,     ///< 8bit gray, 8bit alpha
     PIX_FMT_BGR48LE,   ///< packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as little-endian
     PIX_FMT_BGR48BE,   ///< packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as big-endian
+    PIX_FMT_VDPAU,     ///< HW decoding with VDPAU, Picture.data[3] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
     PIX_FMT_NB,        ///< number of pixel formats, DO NOT USE THIS if you want to link with shared libav* because the number of formats might differ between versions
 };
 
-- 
1.5.4.3

